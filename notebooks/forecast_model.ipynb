{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88a5cb6",
   "metadata": {},
   "source": [
    "# Hourly Demand Forecasting Model\n",
    "\n",
    "**Business Problem**: Predict hourly bike demand to optimize fleet sizing, staffing, and bike redistribution.\n",
    "\n",
    "**Approach**: \n",
    "1. Aggregate journey data to hourly counts\n",
    "2. Engineer temporal features (hour, day of week, month, etc.)\n",
    "3. Train ML models (XGBoost, Random Forest)\n",
    "4. Evaluate and interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a21c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790871f",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_parquet(\"data/journeys_2019_2020_2021.parquet\")\n",
    "\n",
    "# Remove outliers (>24h journeys)\n",
    "df = df[df['Duration'] < 1440].copy()\n",
    "\n",
    "print(f\"Total journeys: {len(df):,}\")\n",
    "print(f\"Date range: {df['Start Date'].min()} to {df['Start Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to hourly demand (total journeys per hour)\n",
    "df['hour_bucket'] = df['Start Date'].dt.floor('h')\n",
    "\n",
    "hourly_demand = df.groupby('hour_bucket').size().reset_index(name='demand')\n",
    "hourly_demand.columns = ['datetime', 'demand']\n",
    "\n",
    "print(f\"Hourly records: {len(hourly_demand):,}\")\n",
    "print(f\"Average hourly demand: {hourly_demand['demand'].mean():.0f} journeys\")\n",
    "hourly_demand.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb38bc6",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Create temporal features that capture cyclical patterns in bike demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e841e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create temporal features for demand forecasting.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic temporal features\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['day_of_week'] = df['datetime'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['day_of_month'] = df['datetime'].dt.day\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['week_of_year'] = df['datetime'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    # Binary features\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['is_rush_hour'] = df['hour'].isin([7, 8, 9, 17, 18, 19]).astype(int)\n",
    "    \n",
    "    # Cyclical encoding (captures circular nature of time)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # Lag features (previous hour's demand)\n",
    "    df['demand_lag_1h'] = df['demand'].shift(1)\n",
    "    df['demand_lag_24h'] = df['demand'].shift(24)  # Same hour yesterday\n",
    "    df['demand_lag_168h'] = df['demand'].shift(168)  # Same hour last week\n",
    "    \n",
    "    # Rolling averages\n",
    "    df['demand_rolling_24h'] = df['demand'].shift(1).rolling(window=24).mean()\n",
    "    df['demand_rolling_7d'] = df['demand'].shift(1).rolling(window=168).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "hourly_demand = create_features(hourly_demand)\n",
    "\n",
    "# Drop rows with NaN (from lag features)\n",
    "hourly_demand = hourly_demand.dropna()\n",
    "\n",
    "print(f\"Features created. Final dataset: {len(hourly_demand):,} rows\")\n",
    "print(f\"\\nFeatures: {list(hourly_demand.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b10ee6",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "Use time-based split (not random) to respect temporal ordering - train on earlier data, test on later data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_cols = [\n",
    "    'hour', 'day_of_week', 'day_of_month', 'month', 'year', 'week_of_year',\n",
    "    'is_weekend', 'is_rush_hour',\n",
    "    'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'month_sin', 'month_cos',\n",
    "    'demand_lag_1h', 'demand_lag_24h', 'demand_lag_168h',\n",
    "    'demand_rolling_24h', 'demand_rolling_7d'\n",
    "]\n",
    "\n",
    "X = hourly_demand[feature_cols]\n",
    "y = hourly_demand['demand']\n",
    "\n",
    "# Time-based split: Train on 2019-2020, Test on 2021\n",
    "train_mask = hourly_demand['year'] < 2021\n",
    "X_train, X_test = X[train_mask], X[~train_mask]\n",
    "y_train, y_test = y[train_mask], y[~train_mask]\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples ({hourly_demand[train_mask]['datetime'].min().date()} to {hourly_demand[train_mask]['datetime'].max().date()})\")\n",
    "print(f\"Test set: {len(X_test):,} samples ({hourly_demand[~train_mask]['datetime'].min().date()} to {hourly_demand[~train_mask]['datetime'].max().date()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c9303",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Train multiple models and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=15, \n",
    "        min_samples_split=5,\n",
    "        n_jobs=-1, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    # MAPE calculation (handle zeros by adding small epsilon)\n",
    "    train_mape = np.mean(np.abs((y_train - y_pred_train) / (y_train + 1e-8))) * 100\n",
    "    test_mape = np.mean(np.abs((y_test - y_pred_test) / (y_test + 1e-8))) * 100\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_mae': mean_absolute_error(y_train, y_pred_train),\n",
    "        'test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        'train_r2': r2_score(y_train, y_pred_train),\n",
    "        'test_r2': r2_score(y_test, y_pred_test),\n",
    "        'train_mape': train_mape,\n",
    "        'test_mape': test_mape,\n",
    "\n",
    "        'predictions': y_pred_test\n",
    "    }\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(f\"  Test MAE: {results[name]['test_mae']:.1f} | Test MAPE: {results[name]['test_mape']:.1f}% | Test R²: {results[name]['test_r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c32bc8",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    name: {\n",
    "        'Train MAE': f\"{r['train_mae']:.1f}\",\n",
    "        'Test MAE': f\"{r['test_mae']:.1f}\",\n",
    "        'Train RMSE': f\"{r['train_rmse']:.1f}\",\n",
    "        'Test RMSE': f\"{r['test_rmse']:.1f}\",\n",
    "        'Train MAPE': f\"{r['train_mape']:.1f}%\",\n",
    "        'Test MAPE': f\"{r['test_mape']:.1f}%\",\n",
    "        'Train R²': f\"{r['train_r2']:.3f}\",\n",
    "        'Test R²': f\"{r['test_r2']:.3f}\"\n",
    "    }\n",
    "    for name, r in results.items()\n",
    "}).T\n",
    "\n",
    "print(\"=== Model Performance Comparison ===\\n\")\n",
    "print(comparison_df.to_string())\n",
    "\n",
    "# Identify best model\n",
    "# Selection criteria: MAE (Mean Absolute Error)\n",
    "# Rationale: \n",
    "# - MAE is operationally meaningful: \"We're off by X bikes/hour on average\"\n",
    "# - Directly informs fleet buffer sizing decisions\n",
    "# - MAPE is inflated by low-demand overnight hours (being off by 10 bikes at 3AM = 50% error)\n",
    "# - High-demand accuracy matters more than low-demand percentage accuracy\n",
    "\n",
    "best_model_name = min(results, key=lambda x: results[x]['test_mae'])\n",
    "print(f\"\\n Best model (lowest Test MAE): {best_model_name}\")\n",
    "print(f\"  - MAE chosen over MAPE: MAPE inflated by low-demand overnight hours where accuracy matters less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527499c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['Mean Absolute Error', 'R² Score'])\n",
    "\n",
    "model_names = list(results.keys())\n",
    "colors = ['#3498DB', '#E74C3C', '#27AE60']\n",
    "\n",
    "# MAE comparison\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=model_names,\n",
    "        y=[results[m]['train_mae'] for m in model_names],\n",
    "        name='Train',\n",
    "        marker_color='#3498DB',\n",
    "        text=[f\"{results[m]['train_mae']:.0f}\" for m in model_names],\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=model_names,\n",
    "        y=[results[m]['test_mae'] for m in model_names],\n",
    "        name='Test',\n",
    "        marker_color='#E74C3C',\n",
    "        text=[f\"{results[m]['test_mae']:.0f}\" for m in model_names],\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# R² comparison\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=model_names,\n",
    "        y=[results[m]['train_r2'] for m in model_names],\n",
    "        name='Train',\n",
    "        marker_color='#3498DB',\n",
    "        text=[f\"{results[m]['train_r2']:.2f}\" for m in model_names],\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=model_names,\n",
    "        y=[results[m]['test_r2'] for m in model_names],\n",
    "        name='Test',\n",
    "        marker_color='#E74C3C',\n",
    "        text=[f\"{results[m]['test_r2']:.2f}\" for m in model_names],\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='<b>Model Performance Comparison</b>',\n",
    "    height=450,\n",
    "    width=1000,\n",
    "    barmode='group'\n",
    ")\n",
    "fig.update_yaxes(title_text='MAE (journeys/hour)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='R² Score', row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717346c",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "Understanding which factors drive bike demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4011902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from best model (XGBoost)\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=importance_df['feature'],\n",
    "        x=importance_df['importance'],\n",
    "        orientation='h',\n",
    "        marker_color='#2C3E50'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'<b>Feature Importance ({best_model_name})</b>',\n",
    "        xaxis_title='Importance',\n",
    "        height=600,\n",
    "        width=800,\n",
    "        margin=dict(l=200)\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n=== Top 5 Most Important Features ===\")\n",
    "    for _, row in importance_df.tail(5).iloc[::-1].iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080456f6",
   "metadata": {},
   "source": [
    "## 7. Predictions vs Actual\n",
    "\n",
    "Visualize how well the model predicts demand over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test set with predictions\n",
    "test_df = hourly_demand[~train_mask].copy()\n",
    "test_df['predicted'] = results[best_model_name]['predictions']\n",
    "\n",
    "# Plot a 2-week sample for clarity\n",
    "sample_start = '2021-06-01'\n",
    "sample_end = '2021-06-14'\n",
    "sample = test_df[(test_df['datetime'] >= sample_start) & (test_df['datetime'] <= sample_end)]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sample['datetime'],\n",
    "    y=sample['demand'],\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='#3498DB', width=1.5)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sample['datetime'],\n",
    "    y=sample['predicted'],\n",
    "    mode='lines',\n",
    "    name='Predicted',\n",
    "    line=dict(color='#E74C3C', width=1.5, dash='dot')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'<b>Actual vs Predicted Hourly Demand</b><br><sup>Sample: {sample_start} to {sample_end}</sup>',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Hourly Demand (journeys)',\n",
    "    height=500,\n",
    "    width=1100,\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b67cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Actual vs Predicted\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test,\n",
    "    y=results[best_model_name]['predictions'],\n",
    "    mode='markers',\n",
    "    marker=dict(color='#3498DB', opacity=0.3, size=4),\n",
    "    name='Predictions'\n",
    "))\n",
    "\n",
    "# Perfect prediction line\n",
    "max_val = max(y_test.max(), results[best_model_name]['predictions'].max())\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, max_val],\n",
    "    y=[0, max_val],\n",
    "    mode='lines',\n",
    "    line=dict(color='#E74C3C', dash='dash'),\n",
    "    name='Perfect Prediction'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'<b>Actual vs Predicted ({best_model_name})</b><br><sup>R² = {results[best_model_name][\"test_r2\"]:.3f}</sup>',\n",
    "    xaxis_title='Actual Demand',\n",
    "    yaxis_title='Predicted Demand',\n",
    "    height=500,\n",
    "    width=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c185176",
   "metadata": {},
   "source": [
    "## 8. Business Application: Demand by Hour of Week\n",
    "\n",
    "Show predicted demand patterns the client can use for operational planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facaff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of average demand by day of week and hour\n",
    "heatmap_data = test_df.groupby(['day_of_week', 'hour'])['demand'].mean().unstack()\n",
    "\n",
    "# Rename for clarity\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "heatmap_data.index = day_names\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_data.values,\n",
    "    x=[f'{h:02d}:00' for h in range(24)],\n",
    "    y=day_names,\n",
    "    colorscale='RdYlGn_r',\n",
    "    colorbar=dict(title='Avg Demand')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='<b>Average Hourly Demand by Day of Week</b><br><sup>Use for staffing and bike redistribution planning</sup>',\n",
    "    xaxis_title='Hour of Day',\n",
    "    yaxis_title='Day of Week',\n",
    "    height=400,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n=== Key Insights for Operations ===\")\n",
    "peak_hour = test_df.groupby('hour')['demand'].mean().idxmax()\n",
    "peak_day = test_df.groupby('day_of_week')['demand'].mean().idxmax()\n",
    "print(f\"• Peak hour: {peak_hour}:00\")\n",
    "print(f\"• Peak day: {day_names[peak_day]}\")\n",
    "print(f\"• Average hourly demand: {test_df['demand'].mean():.0f} journeys\")\n",
    "print(f\"• Peak hourly demand: {test_df['demand'].max():,.0f} journeys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f059c180",
   "metadata": {},
   "source": [
    "## 9. Summary & Business Recommendations\n",
    "\n",
    "### Model Performance\n",
    "- The model can predict hourly demand with high accuracy, enabling proactive operational planning.\n",
    "\n",
    "### Business Applications\n",
    "1. **Fleet Sizing**: Use predicted peak demand to determine required bike inventory\n",
    "2. **Staff Scheduling**: Align maintenance/redistribution crews with demand valleys (night, early morning)\n",
    "3. **Dynamic Pricing**: Increase prices during predicted high-demand periods to manage demand\n",
    "4. **Bike Redistribution**: Pre-position bikes before predicted morning/evening rushes\n",
    "\n",
    "### Next Steps\n",
    "- Add external data (weather, events, holidays) to improve predictions\n",
    "- Build station-level forecasting for granular redistribution planning\n",
    "- Implement real-time forecasting pipeline for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
